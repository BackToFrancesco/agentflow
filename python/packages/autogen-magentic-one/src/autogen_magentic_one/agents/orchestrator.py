import json
from typing import Any, Dict, List, Optional

from autogen_core.base import AgentProxy, CancellationToken, MessageContext, TopicId
from autogen_core.components import default_subscription
from autogen_core.components.models import (
    AssistantMessage,
    ChatCompletionClient,
    LLMMessage,
    SystemMessage,
    UserMessage,
)

from ..messages import BroadcastMessage, OrchestrationEvent, ResetMessage
from .base_orchestrator import BaseOrchestrator
from .orchestrator_prompts import (
    ORCHEORCHESTRATOR_SUMMARIZE_STEPS_SYSTEM_MESSAGE,
    ORCHEORCHESTRATOR_SUMMARIZE_STEPS_SYSTEM_MESSAGE_AUTOFORM,
    ORCHESTRATOR_CLOSED_BOOK_PROMPT,
    ORCHESTRATOR_CLOSED_BOOK_PROMPT_AUTOFORM,
    ORCHESTRATOR_CREATE_COMPLETION_PLAN_PROMPT,
    ORCHESTRATOR_CREATE_COMPLETION_PLAN_PROMPT_AUTOFORM,
    ORCHESTRATOR_CREATE_COMPLETION_PLAN_SYSTEM_MESSAGE,
    ORCHESTRATOR_CREATE_COMPLETION_PLAN_SYSTEM_MESSAGE_AUTOFORM,
    ORCHESTRATOR_GET_FINAL_ANSWER,
    ORCHESTRATOR_LEDGER_PROMPT,
    ORCHESTRATOR_LEDGER_PROMPT_AUTOFORM,
    ORCHESTRATOR_PLAN_PROMPT,
    ORCHESTRATOR_PLAN_PROMPT_AUTOFORM,
    ORCHESTRATOR_SUMMARIZE_STEPS_PROMPT,
    ORCHESTRATOR_SUMMARIZE_STEPS_PROMPT_AUTOFORM,
    ORCHESTRATOR_SYNTHESIZE_PROMPT,
    ORCHESTRATOR_SYNTHESIZE_PROMPT_AUTOFORM,
    ORCHESTRATOR_SYSTEM_MESSAGE,
    ORCHESTRATOR_TASK_COMPLETED_CONFIRMATION_PROMPT,
    ORCHESTRATOR_TASK_COMPLETED_CONFIRMATION_PROMPT_AUTOFORM,
    ORCHESTRATOR_UPDATE_FACTS_PROMPT,
    ORCHESTRATOR_UPDATE_FACTS_PROMPT_AUTOFORM,
    ORCHESTRATOR_UPDATE_PLAN_PROMPT,
    ORCHESTRATOR_UPDATE_PLAN_PROMPT_AUTOFORM,
)


@default_subscription
class RoundRobinOrchestrator(BaseOrchestrator):
    """A simple orchestrator that selects agents in a round-robin fashion."""

    def __init__(
        self,
        agents: List[AgentProxy],
        description: str = "Round robin orchestrator",
        max_rounds: int = 20,
    ) -> None:
        super().__init__(agents=agents, description=description, max_rounds=max_rounds)

    async def _select_next_agent(self, message: LLMMessage) -> AgentProxy:
        self._current_index = (self._num_rounds) % len(self._agents)
        return self._agents[self._current_index]


@default_subscription
class LedgerOrchestrator(BaseOrchestrator):
    """The LedgerOrhestrator is the orchestrator used by MagenticOne to solve tasks.
    It uses a ledger (implemented as a JSON generated by the LLM) to keep track of task progress and select the next agent that should speak."""

    DEFAULT_SYSTEM_MESSAGES = [
        SystemMessage(ORCHESTRATOR_SYSTEM_MESSAGE),
    ]

    def __init__(
        self,
        agents: List[AgentProxy],
        model_client: ChatCompletionClient,
        description: str = "Ledger-based orchestrator",
        system_messages: List[SystemMessage] = DEFAULT_SYSTEM_MESSAGES,
        closed_book_prompt: str = ORCHESTRATOR_CLOSED_BOOK_PROMPT,
        plan_prompt: str = ORCHESTRATOR_PLAN_PROMPT,
        synthesize_prompt: str = ORCHESTRATOR_SYNTHESIZE_PROMPT,
        ledger_prompt: str = ORCHESTRATOR_LEDGER_PROMPT,
        update_facts_prompt: str = ORCHESTRATOR_UPDATE_FACTS_PROMPT,
        update_plan_prompt: str = ORCHESTRATOR_UPDATE_PLAN_PROMPT,
        summarize_steps_prompt: str = ORCHESTRATOR_SUMMARIZE_STEPS_PROMPT,
        create_completition_plan_prompt: str = ORCHESTRATOR_CREATE_COMPLETION_PLAN_PROMPT,
        task_completed_confirmation_prompt: str = ORCHESTRATOR_TASK_COMPLETED_CONFIRMATION_PROMPT,
        max_rounds: int = 20,
        max_time: float = float("inf"),
        max_stalls_before_replan: int = 3,
        max_replans: int = 3,
        return_final_answer: bool = False,
        infinite_conversation: bool = False,
        final_check: bool = False,
        autoform_prompt: bool = False
    ) -> None:
        super().__init__(agents=agents, description=description, max_rounds=max_rounds, max_time=max_time)

        self._model_client = model_client

        # prompt-based parameters
        self._system_messages = system_messages
        self._closed_book_prompt = ORCHESTRATOR_CLOSED_BOOK_PROMPT_AUTOFORM if autoform_prompt else closed_book_prompt
        self._plan_prompt = ORCHESTRATOR_PLAN_PROMPT_AUTOFORM if autoform_prompt else plan_prompt
        self._synthesize_prompt = ORCHESTRATOR_SYNTHESIZE_PROMPT_AUTOFORM if autoform_prompt else synthesize_prompt
        self._ledger_prompt = ORCHESTRATOR_LEDGER_PROMPT_AUTOFORM if autoform_prompt else ledger_prompt
        self._update_facts_prompt = ORCHESTRATOR_UPDATE_FACTS_PROMPT_AUTOFORM if autoform_prompt else update_facts_prompt
        self._update_plan_prompt = ORCHESTRATOR_UPDATE_PLAN_PROMPT_AUTOFORM if autoform_prompt else update_plan_prompt
        self._summarize_steps_prompt = ORCHESTRATOR_SUMMARIZE_STEPS_PROMPT_AUTOFORM if autoform_prompt else summarize_steps_prompt
        self._create_completion_plan_prompt = ORCHESTRATOR_CREATE_COMPLETION_PLAN_PROMPT_AUTOFORM if autoform_prompt else create_completition_plan_prompt
        self._task_completed_confirmation_prompt = ORCHESTRATOR_TASK_COMPLETED_CONFIRMATION_PROMPT_AUTOFORM if autoform_prompt else task_completed_confirmation_prompt
        self._summarize_steps_system_message = ORCHEORCHESTRATOR_SUMMARIZE_STEPS_SYSTEM_MESSAGE_AUTOFORM if autoform_prompt else ORCHEORCHESTRATOR_SUMMARIZE_STEPS_SYSTEM_MESSAGE
        self._create_completion_plan_system_message = ORCHESTRATOR_CREATE_COMPLETION_PLAN_SYSTEM_MESSAGE_AUTOFORM if autoform_prompt else ORCHESTRATOR_CREATE_COMPLETION_PLAN_SYSTEM_MESSAGE



        self._chat_history: List[LLMMessage] = []
        self._should_replan = True
        self._max_stalls_before_replan = max_stalls_before_replan
        self._stall_counter = 0
        self._max_replans = max_replans
        self._replan_counter = 0
        self._return_final_answer = return_final_answer
        self._infinite_conversation = infinite_conversation
        self._final_check = final_check
        self._autoform_prompt = autoform_prompt

        self._team_description = ""
        self._task = ""
        self._facts = ""
        self._plan = ""

    async def _summarize_steps(self, cancellation_token: Optional[CancellationToken] = None) -> str:
        summary_response = await self._model_client.create(
            messages=[
                SystemMessage(self._summarize_steps_system_message),
                UserMessage(self._get_summarize_steps_prompt(task=self._task, conversation=self._chat_history), source=self.metadata["type"])
            ] + self._chat_history,
            cancellation_token=cancellation_token
        )

        return summary_response.content

    async def _create_completion_plan(self, initial_request: str, reason: str, cancellation_token: Optional[CancellationToken] = None) -> str:
        plan_response = await self._model_client.create(
            messages=[
                SystemMessage(self._create_completion_plan_system_message),
                UserMessage(self._get_create_completion_plan_prompt(initial_request=initial_request, reason=reason), source=self.metadata["type"])
            ],
            cancellation_token=cancellation_token
        )
        print("PLAN RESPONSE:\n")
        print(plan_response)
        return plan_response.content

    def _get_closed_book_prompt(self, task: str) -> str:
        return self._closed_book_prompt.format(task=task)

    def _get_plan_prompt(self, team: str) -> str:
        return self._plan_prompt.format(team=team)

    def _get_synthesize_prompt(self, task: str, team: str, facts: str, plan: str) -> str:
        return self._synthesize_prompt.format(task=task, team=team, facts=facts, plan=plan)

    def _get_ledger_prompt(self, task: str, team: str, names: List[str]) -> str:
        return self._ledger_prompt.format(task=task, team=team, names=names)

    def _get_update_facts_prompt(self, task: str, facts: str) -> str:
        return self._update_facts_prompt.format(task=task, facts=facts)

    def _get_update_plan_prompt(self, team: str) -> str:
        return self._update_plan_prompt.format(team=team)

    def _get_summarize_steps_prompt(self, task: str, conversation: str) -> str:
        return self._summarize_steps_prompt.format(task=task, conversation=conversation)
    
    def _get_create_completion_plan_prompt(self, initial_request: str, reason: str) -> str:
        return self._create_completion_plan_prompt.format(initial_request=initial_request, reason=reason)
    
    def _get_task_completed_confirmation_prompt(self, task: str, steps_summary: str) -> str:
        return self._task_completed_confirmation_prompt.format(task=task, steps_summary=steps_summary)

    async def _get_team_description(self) -> str:
        # a single string description of all agents in the team
        team_description = ""
        for agent in self._agents:
            metadata = await agent.metadata
            name = metadata["type"]
            description = metadata["description"]
            team_description += f"{name}: {description}\n"
        return team_description

    async def _get_team_names(self) -> List[str]:
        return [(await agent.metadata)["type"] for agent in self._agents]

    def _get_message_str(self, message: LLMMessage) -> str:
        if isinstance(message.content, str):
            return message.content
        else:
            result = ""
            for content in message.content:
                if isinstance(content, str):
                    result += content + "\n"
            assert len(result) > 0
        return result

    async def _initialize_task(self, task: str, cancellation_token: Optional[CancellationToken] = None) -> None:
        # called the first time a task is received
        self._task = task
        self._team_description = await self._get_team_description()

        # Shallow-copy the conversation
        planning_conversation = [m for m in self._chat_history]

        # 1. GATHER FACTS
        # create a closed book task and generate a response and update the chat history
        planning_conversation.append(
            UserMessage(content=self._get_closed_book_prompt(self._task), source=self.metadata["type"])
        )
        response = await self._model_client.create(
            self._system_messages + planning_conversation, cancellation_token=cancellation_token
        )

        assert isinstance(response.content, str)
        self._facts = response.content
        planning_conversation.append(AssistantMessage(content=self._facts, source=self.metadata["type"]))

        # 2. CREATE A PLAN
        ## plan based on available information
        planning_conversation.append(
            UserMessage(content=self._get_plan_prompt(self._team_description), source=self.metadata["type"])
        )
        response = await self._model_client.create(
            self._system_messages + planning_conversation, cancellation_token=cancellation_token
        )

        assert isinstance(response.content, str)
        self._plan = response.content

        # At this point, the planning conversation is dropped.

    async def _update_facts_and_plan(self, cancellation_token: Optional[CancellationToken] = None) -> None:
        # called when the orchestrator decides to replan

        # Shallow-copy the conversation
        planning_conversation = [m for m in self._chat_history]

        # Update the facts
        planning_conversation.append(
            UserMessage(content=self._get_update_facts_prompt(self._task, self._facts), source=self.metadata["type"])
        )
        response = await self._model_client.create(
            self._system_messages + planning_conversation, cancellation_token=cancellation_token
        )

        assert isinstance(response.content, str)
        self._facts = response.content
        planning_conversation.append(AssistantMessage(content=self._facts, source=self.metadata["type"]))

        # Update the plan
        planning_conversation.append(
            UserMessage(content=self._get_update_plan_prompt(self._team_description), source=self.metadata["type"])
        )
        response = await self._model_client.create(
            self._system_messages + planning_conversation, cancellation_token=cancellation_token
        )

        assert isinstance(response.content, str)
        self._plan = response.content

    async def update_ledger(self, cancellation_token: Optional[CancellationToken] = None) -> Dict[str, Any]:
        # updates the ledger at each turn
        max_json_retries = 10

        team_description = await self._get_team_description()
        names = await self._get_team_names()
        ledger_prompt = self._get_ledger_prompt(self._task, team_description, names)

        ledger_user_messages: List[LLMMessage] = [UserMessage(content=ledger_prompt, source=self.metadata["type"])]

        # retries in case the LLM does not return a valid JSON
        assert max_json_retries > 0
        for _ in range(max_json_retries):
            ledger_response = await self._model_client.create(
                self._system_messages + self._chat_history + ledger_user_messages,
                json_output=True,
                cancellation_token=cancellation_token,
            )
            ledger_str = ledger_response.content

            try:
                assert isinstance(ledger_str, str)
                ledger_dict: Dict[str, Any] = json.loads(ledger_str)
                required_keys = [
                    "is_request_satisfied",
                    "is_in_loop",
                    "is_progress_being_made",
                    "next_speaker",
                    "instruction_or_question",
                ]
                key_error = False
                for key in required_keys:
                    if key not in ledger_dict:
                        ledger_user_messages.append(AssistantMessage(content=ledger_str, source="self"))
                        ledger_user_messages.append(
                            UserMessage(content=f"KeyError: '{key}'", source=self.metadata["type"])
                        )
                        key_error = True
                        break
                    if "answer" not in ledger_dict[key]:
                        ledger_user_messages.append(AssistantMessage(content=ledger_str, source="self"))
                        ledger_user_messages.append(
                            UserMessage(content=f"KeyError: '{key}.answer'", source=self.metadata["type"])
                        )
                        key_error = True
                        break
                if key_error:
                    continue
                return ledger_dict
            except json.JSONDecodeError as e:
                self.logger.info(
                    OrchestrationEvent(
                        f"{self.metadata['type']} (error)",
                        f"Failed to parse ledger information: {ledger_str}",
                    )
                )
                raise e

        raise ValueError("Failed to parse ledger information after multiple retries.")

    async def _prepare_final_answer(self, cancellation_token: Optional[CancellationToken] = None) -> str:
        # called when the task is complete

        final_message = UserMessage(
            content=ORCHESTRATOR_GET_FINAL_ANSWER.format(task=self._task), source=self.metadata["type"]
        )
        response = await self._model_client.create(
            self._system_messages + self._chat_history + [final_message], cancellation_token=cancellation_token
        )

        assert isinstance(response.content, str)

        return response.content

    async def _handle_broadcast(self, message: BroadcastMessage, ctx: MessageContext) -> None:
        self._chat_history.append(message.content)
        await super()._handle_broadcast(message, ctx)

    async def _select_next_agent(
        self, message: LLMMessage, cancellation_token: Optional[CancellationToken] = None
    ) -> Optional[AgentProxy]:
        # the main orchestrator loop
        # Check if the task is still unset, in which case this message contains the task string
        if len(self._task) == 0:
            await self._initialize_task(self._get_message_str(message), cancellation_token)

            # At this point the task, plan and facts shouls all be set
            assert len(self._task) > 0
            assert len(self._facts) > 0
            assert len(self._plan) > 0
            assert len(self._team_description) > 0

            # Send everyone the plan
            synthesized_prompt = self._get_synthesize_prompt(
                self._task, self._team_description, self._facts, self._plan
            )
            topic_id = TopicId("default", self.id.key)
            await self.publish_message(
                BroadcastMessage(content=UserMessage(content=synthesized_prompt, source=self.metadata["type"])),
                topic_id=topic_id,
                cancellation_token=cancellation_token,
            )

            self.logger.info(
                OrchestrationEvent(
                    f"{self.metadata['type']} (thought)",
                    f"Initial plan:\n{synthesized_prompt}",
                )
            )

            self._replan_counter = 0
            self._stall_counter = 0

            synthesized_message = AssistantMessage(content=synthesized_prompt, source=self.metadata["type"])
            self._chat_history.append(synthesized_message)

            # Answer from this synthesized message
            return await self._select_next_agent(synthesized_message, cancellation_token)

        # Orchestrate the next step
        ledger_dict = await self.update_ledger(cancellation_token)
        self.logger.info(
            OrchestrationEvent(
                f"{self.metadata['type']} (update ledger)",
                f"Updated Ledger:\n{json.dumps(ledger_dict, indent=2)}",
            )
        )

        # Task is complete
        # First, get all agent types asynchronously
        agent_types = [await agent.metadata for agent in self._agents]
        agent_types = [metadata["type"] for metadata in agent_types]

        # Then use the list of agent types in the condition
        request_satisfied = False
        if ledger_dict["is_request_satisfied"]["answer"] is True and ((not self._infinite_conversation) or (self._infinite_conversation and ledger_dict["next_speaker"]["answer"] != "UserProxy")):
            if self._final_check:
                # Generate a summary of steps taken                                                                                                                                                                   
                steps_summary = await self._summarize_steps(cancellation_token)                                                                                                                                       
                                                                                                                                                                                                                    
                self.logger.info(
                OrchestrationEvent(
                        f"{self.metadata['type']} (thought)",
                        f"Steps taken so far:\n{steps_summary}",
                    )
                )

                # LLM call to confirm if the request is completely satisfied
                confirmation_response = await self._model_client.create(
                    messages=[
                        SystemMessage("You are an AI assistant tasked with reviewing the steps made so far and determining if requests have been satisfied."),
                        UserMessage(self._get_task_completed_confirmation_prompt(task=self._task, steps_summary = steps_summary), source=self.metadata["type"])
                    ],
                    json_output=True,
                    cancellation_token=cancellation_token
                )
                
                confirmation_result = json.loads(confirmation_response.content)
                
                self.logger.info(
                    OrchestrationEvent(
                        f"{self.metadata['type']} (thought)",
                        f"Request satisfaction confirmation: {json.dumps(confirmation_result, indent=2)}",
                    )
                )

                request_satisfied = confirmation_result["request_satisfied"]
                if request_satisfied:
                    self.logger.info(
                        OrchestrationEvent(
                            f"{self.metadata['type']} (thought)",
                            "Request confirmed as satisfied.",
                        )
                    )
            if (request_satisfied or not self._final_check):
                if self._return_final_answer:
                    # generate a final message to summarize the conversation
                    final_answer = await self._prepare_final_answer(cancellation_token)
                    self.logger.info(
                        OrchestrationEvent(
                            f"{self.metadata['type']} (final answer)",
                            f"\n{final_answer}",
                        )
                    )
                self.logger.info(
                    OrchestrationEvent(
                        f"{self.metadata['type']} (thought)",
                        "Request satisfied.",
                    )
                )
                return None
            else:
                self.logger.info(
                    OrchestrationEvent(
                        f"{self.metadata['type']} (thought)",
                        f"Request not fully satisfied. Reason: {confirmation_result['reason']}",
                    )
                )

                # Create a plan to complete the task
                self.logger.info(
                    OrchestrationEvent(
                        f"{self.metadata['type']} (thought)",
                        f"Request not fully satisfied. Reason: {confirmation_result['reason']}",
                    )
                )

                topic_id = TopicId("default", self.id.key)

                # Send everyone the NEW plan
                await self.publish_message(
                    BroadcastMessage(content=UserMessage(content=confirmation_result['reason'], source=self.metadata["type"])),
                    topic_id=topic_id,
                    cancellation_token=cancellation_token,
                )

                synthesized_message = AssistantMessage(content=confirmation_result['reason'], source=self.metadata["type"])
                self._chat_history.append(synthesized_message)

                # Answer from this synthesized message
                return await self._select_next_agent(confirmation_result['reason'], cancellation_token)

        # If the request is not satisfied or we're in a loop, proceed with replanning logic
        if ledger_dict["is_in_loop"]["answer"] or not ledger_dict["is_progress_being_made"]["answer"]:
            self._stall_counter += 1

            # We exceeded our stall counter, so we need to replan, or exit
            if self._stall_counter > self._max_stalls_before_replan:
                self._replan_counter += 1
                self._stall_counter = 0

                # We exceeded our replan counter
                if self._replan_counter > self._max_replans:
                    self.logger.info(
                        OrchestrationEvent(
                            f"{self.metadata['type']} (thought)",
                            "Replan counter exceeded... Terminating.",
                        )
                    )
                    return None
                # Let's create a new plan
                else:
                    self.logger.info(
                        OrchestrationEvent(
                            f"{self.metadata['type']} (thought)",
                            "Stalled or request not fully satisfied.... Replanning...",
                        )
                    )

                    # Update our plan.
                    await self._update_facts_and_plan(cancellation_token)

                    # Reset everyone, then rebroadcast the new plan
                    self._chat_history = [self._chat_history[0]]
                    topic_id = TopicId("default", self.id.key)
                    await self.publish_message(ResetMessage(), topic_id=topic_id, cancellation_token=cancellation_token)

                    # Send everyone the NEW plan
                    synthesized_prompt = self._get_synthesize_prompt(
                        self._task, self._team_description, self._facts, self._plan
                    )
                    await self.publish_message(
                        BroadcastMessage(content=UserMessage(content=synthesized_prompt, source=self.metadata["type"])),
                        topic_id=topic_id,
                        cancellation_token=cancellation_token,
                    )

                    self.logger.info(
                        OrchestrationEvent(
                            f"{self.metadata['type']} (thought)",
                            f"New plan:\n{synthesized_prompt}",
                        )
                    )

                    synthesized_message = AssistantMessage(content=synthesized_prompt, source=self.metadata["type"])
                    self._chat_history.append(synthesized_message)

                    # Answer from this synthesized message
                    return await self._select_next_agent(synthesized_message, cancellation_token)

        # If the request is satisfied and we're not in a loop, we can terminate
        if request_satisfied:
            return None

        # If we goit this far, we were not starting, done, or stuck
        next_agent_name = ledger_dict["next_speaker"]["answer"]
        # find the agent with the next agent name
        for agent in self._agents:
            if (await agent.metadata)["type"] == next_agent_name:
                # broadcast a new message
                instruction = ledger_dict["instruction_or_question"]["answer"]
                user_message = UserMessage(content=instruction, source=self.metadata["type"])
                assistant_message = AssistantMessage(content=instruction, source=self.metadata["type"])
                self.logger.info(OrchestrationEvent(f"{self.metadata['type']} (-> {next_agent_name})", instruction))
                self._chat_history.append(assistant_message)  # My copy
                topic_id = TopicId("default", self.id.key)
                await self.publish_message(
                    BroadcastMessage(content=user_message, request_halt=False),
                    topic_id=topic_id,
                    cancellation_token=cancellation_token,
                )  # Send to everyone else
                return agent

        return None
